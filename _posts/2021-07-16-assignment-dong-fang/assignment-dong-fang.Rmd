---
title: "Data Visualization and Analysis for the Kronos Incident Investigation Using R"
description: |
  VAST Challenge 2021 Mini-Challenge 2.
author:
  - name: DONG Fang
    url: https://www.linkedin.com/in/reginadongf/
    affiliation: School of Computing and Information Systems, Singapore Management University
    affiliation_url: https://scis.smu.edu.sg/
date: 07-16-2021
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc_depth: 5
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.retina = 3,   # To make the figure looks sharper, set the retina value >=3, default is 1 
                      echo = TRUE,      # Show code chunk
                      eval = TRUE,      # Run the code
                      message = FALSE,  # Don't show error massage
                      warning = FALSE)  # Don't show warning massage
```

# 1. Background

## 1.1 Case overview

GAStech is a Tethys-based company having been operating a natural gas production site in the island country of Kronos for over 20 years. It has produced remarkable profits and developed strong relationships with the government of Kronos, but has not been as successful in demonstrating environmental stewardship.

In January, 2014, the leaders of GAStech are celebrating their new-found fortune as a result of the initial public offering of their very successful company. In the midst of this celebration, several employees of GAStech go missing. An organization known as the Protectors of Kronos (POK) is suspected in the disappearance, but things may not be what they seem.

This case is designed aim at helping the law enforcement from Kronos and Tethys investigate the incident by using data visualization techniques. There are 3 challenges in [**VAST Challenge 2021**](https://vast-challenge.github.io/2021/index.html) focusing on different aspects of case analysis. In this report we concentrated on visualization and analysis for Mini-Challenge 2.

## 1.2 Requirement for Mini-Challenge 2

Many of the Abila, Kronos-based employees of GAStech have company cars which are approved for both personal and business use. Those who do not have company cars have the ability to check out company trucks for business use, but these trucks cannot be used for personal business. The vehicles are installed with GPS tracked periodically as long as they are moving. Besides, in order to promote local businesses, Kronos based companies provide a Kronos Kares benefit card to GASTech employees giving them discounts and rewards in exchange for collecting information about their credit card purchases and preferences as recorded on loyalty cards. 

Now the vehicle tracking data for the two weeks prior to the incident, car assignment list, transaction records in credit card and loyal card are available for analyzing.

The challenges to be dealt with are listed below:

**No.**| **Question**
-------|------------------------------------------------------------------------------------------------------------
1      |Using just the credit and loyalty card data, identify the most popular locations, and when they are popular. What anomalies do you see? What corrections would you recommend to correct these anomalies?
2      |Add the vehicle data to your analysis of the credit and loyalty card data. How does your assessment of the anomalies in question 1 change based on this new data? What discrepancies between vehicle, credit, and loyalty card data do you find?
3      |Can you infer the owners of each credit card and loyalty card? What is your evidence? Where are there uncertainties in your method? Where are there uncertainties in the data?
4      |Given the data sources provided, identify potential informal or unofficial relationships among GASTech personnel. Provide evidence for these relationships. 
5      |Do you see evidence of suspicious activity? Identify 1- 10 locations where you believe the suspicious activity is occurring, and why.

The detailed information and all the data needed for Mini-challenge 2 is available in [VAST Challenge 2021 official website](https://vast-challenge.github.io/2021/MC2.html).

# 2. Data Preparation

## 2.1 Data description

The dataset used for Mini-Challenge 2 includes 4 CSV files, a package of ESRI shapefiles of Abila and Kronos, and a tourist map of Abila in JPEG format, as shown in the following screenshot.

![](img/2.1dataset.jpg){width=80%} <br> <p style="text-align:center;"> _Fig.1 Dataset for visualization and analysis_ </p>

The data contents in the CSV files are listed below:

**File**  | **Description**               | **Data Content**
----------|-------------------------------|------------------------------------------------------
car-assignments.csv | A list of vehicle assignments by employee | Employee Last Name <br>	Employee First Name <br> Car ID <br> Current Employment Type (Department) <br>	Current Employment Title (job title)
gps.csv | vehicle tracking data | Timestamp <br> Car ID (integer) <br> Latitude <br> Longitude
cc_data.csv | credit and debit card transaction data | Timestamp <br>	Location (name of the business) <br> Price (real) <br> Last 4 digits of the credit or debit card number
loyalty_data.csv | loyalty card transaction data | Timestamp <br>	Location (name of the business) <br>	Price (real) <br>	Loyalty Number (A 5-character code starting with L that is unique for each card)

## 2.2 Steps for data preparation

### 2.2.1 Installing and launching R Packages 

We used R studio as the tool to import, process and visualize the data. The first thing is to launch necessary R packages for next steps.

The code chunk below is used to install and load the packages.

```{r}
packages = c('ggiraph', 'plotly','DT', 'patchwork', 
             'raster', 'sf','tmap', 'mapview','gifski',
             'tidyverse', 'mlr','lubridate')
for (p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p, character.only = T)
}
```

### 2.2.2 Importing relevent data

First of all we import the CSV file using below code chunk.

```{r}
car_ass <- read_csv("data/car-assignments.csv")
gps <- read_csv("data/gps.csv")
cc <- read_csv("data/cc_data.csv", locale = locale(encoding = "windows-1252"))
loyalty <- read_csv("data/loyalty_data.csv", locale = locale(encoding = "windows-1252"))
```



### 2.2.3 Wrangling the data

As shown below, we need to check if the data type is proper in the imported tibble data table. It's obvious that the *Timestamp* in gps.csv, cc_data.csv and loyalty_data.csv should be in datetime format but now it's in character format. Besides, *CarID* in car-assignments.csv, *id* in gps.csv and *last4ccnum* in cc_data.csv should be converted from numerical data to categorical data.

* car-assignments.csv

```{r echo=FALSE}
glimpse(car_ass)
```

* gps.csv

```{r echo=FALSE}
glimpse(gps)
```

* cc_data.csv

```{r echo=FALSE}
glimpse(cc)
```

* loyalty_data.csv

```{r echo=FALSE}
glimpse(loyalty)
```

We use below code chunk to covert data types.

```{r}
gps$Timestamp = mdy_hms(gps$Timestamp)
cc$timestamp = mdy_hm(cc$timestamp)
loyalty$timestamp = mdy(loyalty$timestamp)

car_ass$CarID = as.character(car_ass$CarID)
gps$id = as.character(gps$id)
cc$last4ccnum = as.character(cc$last4ccnum)
```

As the transaction date in credit and loyalty card data are all in January, we derive days and hours from *timestamp* and display them in different columns in cc_data.csv and loyalty_data.csv using below code chunk. The same as GPS tracking data.

```{r}
cc$day = day(cc$timestamp)
cc$hour = hour(cc$timestamp)
loyalty$day = day(loyalty$timestamp)
gps$day = as.factor(day(gps$Timestamp))
gps$hour = as.factor(hour(gps$Timestamp))
```


### 2.2.4 Exploring and cleaning data

Then we do some exploration for the data and check the missing values by using the code chunks below. Only *CarID* in car-assignments.csv has 9 missing values.

```{r}
knitr::kable(summarizeColumns(car_ass))
```

```{r}
knitr::kable(summarizeColumns(gps))
```

```{r}
knitr::kable(summarizeColumns(cc))
```

```{r}
knitr::kable(summarizeColumns(loyalty))
```

The records containing missing values in car-assignment.csv are shown below. We can see these records are all company trucks not for personal use.

```{r}
car_ass_na <- filter(car_ass, is.na(CarID))
knitr::kable(car_ass_na, format = "html")
```



# 3. Data Visualization

## 3.1 Histogram showing frequecy of transactions

First of all, a 2d histogram with Location by Hour for credit card transaction was built by below code chunk.

```{r}
d <- highlight_key(cc)

gra_1 <- plot_ly(data = d, x = ~as.factor(hour), y = ~location,
                 hovertemplate = paste(
                   " %{yaxis.title.text}: %{y}<br>",
                   "%{xaxis.title.text}: %{x}<br>",
                   "Transaction Count: %{z}",
                   "<extra></extra>")) %>%
  add_histogram2d(colors = "Blues") %>%
  layout(title = "<b>Graph.1 Credit Card Transcation Frequency by Hour</b>",
         xaxis = list(title = "Time", tickmode = "linear"),
         yaxis = list(title="Location", tickmode = "linear")
         )

crosstalk::bscols(gra_1,
                  crosstalk::filter_select("day", "Day", d, ~as.factor(day), multiple = F), widths = 10)
```

Then the 2d histograms with Location by Day for credit card and loyalty card transaction were created as below.

```{r}
gra_2.1 <- plot_ly(data = cc, x = ~as.factor(day), y = ~location,
                 hovertemplate = paste(
                   " %{yaxis.title.text}: %{y}<br>",
                   "%{xaxis.title.text}: %{x}<br>",
                   "Transaction Count: %{z}",
                   "<extra></extra>")) %>%
  add_histogram2d(colors = "Blues") %>%
  layout(annotations = list(text = "Credit Card", showarrow = F, x =17, y=32),
         xaxis = list(tickmode = "linear"),
         yaxis = list(tickmode = "linear")
         )

gra_2.2 <- plot_ly(data = loyalty, x = ~as.factor(day), y = ~location,
                 hovertemplate = paste(
                   " Location: %{y}<br>",
                   "Date of Jan: %{x}<br>",
                   "Transaction Count: %{z}",
                   "<extra></extra>")) %>%
  add_histogram2d(colors = "Purples") %>%
  layout(annotations = list(text = "Loyalty Card", showarrow = F, x =17, y=32),
         xaxis = list(tickmode = "linear"),
         yaxis = list(tickmode = "linear", visible = T)
         )

gra_2 <- subplot(gra_2.1, gra_2.2, nrows = 1, shareY = T) %>%
  layout(title = "<b>Graph.2 Transaction Frequency by Day</b>",
         xaxis = list(title = "Date of Jan"),
         xaxis2 = list(title = "Date of Jan"),
         yaxis = list(title = "Location"),
         autosize = F, width = 900, width2 = 900, height = 400
         )

gra_2
```




## 3.2 Geographical graph showing movement path

Now take the GPS tracking data into account, it's necessary to draw movement path on the tourist map with the GPS tracking data, so that we can see where the employees have gone and gathered together during the two weeks before the disappearance.

The first thing to do is plotting Raster Layer of the tourist map of Abila, Kronos, as the background map, and import Abila GIS data layer.

```{r results='hide'}
bgmap <- raster("data/Geospatial/MC2-tourist.tif")

tm_shape(bgmap) +
tm_rgb(bgmap, r = 1,g = 2,b = 3,
       alpha = NA,
       saturation = 1,
       interpolate = TRUE,
       max.value = 255)

Abila_st <- st_read(dsn = "data/Geospatial",
                    layer = "Abila")
```

The code chunk below is used to convert GPS spatial data into a Simple Feature (SF) data frame.

```{r}
gps_sf <- st_as_sf(gps, 
                   coords = c("long", "lat"),
                   crs = 4326)
```

Then combine the background map and the GPS tracking lines to generate the movement path.

```{r}
gps_path <- gps_sf %>%
  group_by(id, day) %>%
  summarize(m = mean(Timestamp), 
            do_union=FALSE) %>%
  st_cast("LINESTRING")

np = npts(gps_path, by_feature = T)
gps_path2 <- cbind(gps_path, np) %>%
  filter(np > 1) # exclude orphan coordinate records
```



```{r}
#d <- highlight_key(gps_path2)

tmap_mode("view")

m <- tm_shape(bgmap) +
  tm_rgb(bgmap, r = 1,g = 2,b = 3,
       alpha = NA,
       saturation = 1,
       interpolate = TRUE,
       max.value = 255) +
  tm_shape(gps_path2) +
  tm_lines(col = "day") 
  #tm_facets(by = "id")
m
```

```{r}
gps_path_selected <- gps_path2 %>%
  filter(day=="17")

tmap_mode("view")
tm_shape(bgmap) +
  tm_rgb(bgmap, r = 1,g = 2,b = 3,
       alpha = NA,
       saturation = 1,
       interpolate = TRUE,
       max.value = 255) +
  tm_shape(gps_path_selected) +
  tm_lines(col = "id")
 
```

```{r eval=FALSE}
#tmap_mode("view")

m <- tm_shape(bgmap) +
  tm_rgb(bgmap, r = 1,g = 2,b = 3,
       alpha = NA,
       saturation = 1,
       interpolate = TRUE,
       max.value = 255) +
  tm_shape(gps_path2) +
  tm_lines() +
  tm_facets(along = "id")

tmap_animation(m, 
               filename = "img/days.gif",
               delay=40)
```




# 4. Data Analysis and Insights 





# 5. Conclusion
















